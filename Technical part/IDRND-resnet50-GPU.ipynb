{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bfb3bf5e-7842-46c8-a271-9d739e0440c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not detect requirement name for 'git+https://github.com/mjkvaak/ImageDataAugmentor', please specify one with #egg=your_package_name\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.21.3)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 39.3 MB 27.0 MB/s eta 0:00:01    |██████▏                         | 7.5 MB 27.0 MB/s eta 0:00:02     |█████████████████████████▏      | 30.9 MB 27.0 MB/s eta 0:00:01     |███████████████████████████▋    | 33.9 MB 27.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image>=0.16.1\n",
      "  Downloading scikit_image-0.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (30.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.2 MB 27.5 MB/s eta 0:00:01     |██████████████████████▍         | 21.2 MB 27.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.4.60-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.6 MB 401 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.19.1\n",
      "  Downloading scikit_learn-1.0.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n",
      "Collecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.2.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow!=7.1.0,!=7.1.1,>=4.3.0\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading imageio-2.11.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 29.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 21.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (21.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Collecting setuptools-scm>=4\n",
      "  Downloading setuptools_scm-6.3.2-py3-none-any.whl (33 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.2-py3-none-any.whl (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 12.1 MB/s eta 0:00:01     |████████████                    | 440 kB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-1.2.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (58.5.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.14.0)\n",
      "Installing collected packages: threadpoolctl, joblib, scipy, scikit-learn, opencv-python-headless, qudida, PyYAML, tomli, setuptools-scm, fonttools, kiwisolver, pillow, cycler, matplotlib, networkx, PyWavelets, imageio, tifffile, scikit-image, albumentations\n",
      "Successfully installed PyWavelets-1.2.0 PyYAML-6.0 albumentations-1.1.0 cycler-0.11.0 fonttools-4.28.2 imageio-2.11.1 joblib-1.1.0 kiwisolver-1.3.2 matplotlib-3.5.0 networkx-2.6.3 opencv-python-headless-4.5.4.60 pillow-8.4.0 qudida-0.0.4 scikit-image-0.18.3 scikit-learn-1.0.1 scipy-1.7.2 setuptools-scm-6.3.2 threadpoolctl-3.0.0 tifffile-2021.11.2 tomli-1.2.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 3.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle) (2.22.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 3.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle) (1.25.8)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 7.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73052 sha256=77b887cc70bbfb2afef0c96331d26439fed1c4dc729cb8ecd69a10a4fcc45feb\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: tqdm, text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-5.0.2 text-unidecode-1.3 tqdm-4.62.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 4.0 MB/s eta 0:00:01    |████████████████▌               | 5.9 MB 4.0 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.4\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.21.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1308 sha256=45e12d7bb9f07b535ae857d2ca96d57779662613990f16c4814dbc7a946a94b8\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.3)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (58.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2021.11.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.2.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (8.4.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.11.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.28.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (6.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib!=3.0.0,>=2.0.0->scikit-image) (58.5.2)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.21.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.7.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (4.28.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (21.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (58.5.2)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.28.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.3)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib) (58.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.3 MB 77.0 MB/s eta 0:00:01    |████████                        | 15.2 MB 3.4 MB/s eta 0:00:14\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/bin/bash: wand: command not found\n"
     ]
    }
   ],
   "source": [
    "!pip install -e 'git+https://github.com/mjkvaak/ImageDataAugmentor'\n",
    "!pip install -U albumentations\n",
    "!pip install kaggle\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install tensorflow\n",
    "!pip install scikit-image\n",
    "!pip install keras\n",
    "!pip install seaborn \n",
    "!pip install matplotlib\n",
    "# RUN apt-get update && apt-get install -y python3-opencv\n",
    "# RUN pip install opencv-python\n",
    "!pip install opencv-python\n",
    "!wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#from wand.image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "# my output was => ['/device:CPU:0']\n",
    "# good output must be => ['/device:CPU:0', '/device:GPU:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1528776364144594504\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1383149979\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7836271992578610828\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "386dc00c-c8eb-4bcd-a7f7-09a2c6c63396",
    "outputId": "1c15917b-5253-404e-a9aa-98cd62aecc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "82acca04-1b23-42a9-b003-d64b068391f6"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8280/2679519511.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(device, enable)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m   \"\"\"\n\u001b[1;32m--> 716\u001b[1;33m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(self, dev, enable)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m       raise RuntimeError(\n\u001b[0m\u001b[0;32m   1560\u001b[0m           \"Physical devices cannot be modified after being initialized\")\n\u001b[0;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /root/.kaggle\n",
    "!cp kaggle.json /root/.kaggle\n",
    "!ls /root/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 476 GiB\n",
      "Used: 129 GiB\n",
      "Free: 347 GiB\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "\n",
    "print(\"Total: %d GiB\" % (total // (2**30)))\n",
    "print(\"Used: %d GiB\" % (used // (2**30)))\n",
    "print(\"Free: %d GiB\" % (free // (2**30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading idrd-train-set.zip to /root\n",
      "100%|█████████████████████████████████████▉| 27.1G/27.1G [09:48<00:00, 54.3MB/s]\n",
      "100%|██████████████████████████████████████| 27.1G/27.1G [09:48<00:00, 49.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d nurmukhammed7/idrd-train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q idrd-train-set.zip -d idrd-train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "25002948-af0b-4faa-8075-1d8414dd90d5"
   },
   "outputs": [],
   "source": [
    "# PATH = '2020-11-30b_resnext50_32x4d.pth'\n",
    "\n",
    "# model = torch.load(PATH, map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f71aacc8-4355-41cf-a3fd-dee313b30c3b"
   },
   "outputs": [],
   "source": [
    "data_train = r\"E:\\LivenessDetectionDatasets\\IDR&D\\data\"\n",
    "labels = ['2dmask', 'printed', 'real', 'replay']\n",
    "image_size = 160\n",
    "#\"C:\\Users\\user\\Desktop\\Liveness Detection\\JUPYTER NOTEBOOKS\\Ternaus works\\dataset\\data\\2dmask\\2dmask_2\\2dmask_2_01.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eda70bd9-0513-47c4-9ef0-4d49bc3dde6d",
    "outputId": "3d6ceb29-0171-417d-eb2b-4621892aa2b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 433/433 [00:29<00:00, 14.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5036/5036 [05:42<00:00, 14.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2048/2048 [03:08<00:00, 10.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4014/4014 [05:34<00:00, 11.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "def image_reader(data_train):\n",
    "    for label in labels:\n",
    "        join_label = os.path.join(data_train, label)\n",
    "        for label_folder in tqdm(os.listdir(join_label)):\n",
    "            join_folder = os.path.join(join_label, label_folder)\n",
    "            for folder_image in os.listdir(join_folder):\n",
    "                try:\n",
    "                    img_path = os.path.join(join_folder, folder_image)\n",
    "                    image = cv2.imread(img_path)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (image_size, image_size))\n",
    "                    X.append(image)\n",
    "                    y.append(labels.index(label))\n",
    "                except: \n",
    "                    pass\n",
    "    return X, y\n",
    "\n",
    "X, y = image_reader(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d7f3da72-a585-48b2-a714-af325ada27f1"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57655, 160, 160, 3) (57655,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66d1830f-178e-4968-a9a2-fc2e93430c7d",
    "outputId": "8b772587-6fd5-4704-d7b6-be7211aa1a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25180\n",
       "3    20070\n",
       "2    10240\n",
       "0     2165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a994481e-3bac-4fd9-898d-b345020aecff"
   },
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0b3b5993-4583-4358-8746-c9177990eb5a"
   },
   "outputs": [],
   "source": [
    "from albumentations import SmallestMaxSize, RandomResizedCrop, ColorJitter, Blur, Normalize, CenterCrop, Compose\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "68b981fe-a2de-4f30-b62b-28da5f88c5c8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ImageDataAugmentor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4291/1732663638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mImageDataAugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_augmentor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ImageDataAugmentor'"
     ]
    }
   ],
   "source": [
    "from ImageDataAugmentor.image_data_augmentor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Input,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5ce162f4-2db4-4113-a30a-229e4432b97a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Compose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1543918439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_aug = Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mSmallestMaxSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mColorJitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_apply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrightness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Compose' is not defined"
     ]
    }
   ],
   "source": [
    "train_aug = Compose([\n",
    "    SmallestMaxSize(always_apply=False, max_size=256, p=1),\n",
    "    CenterCrop(always_apply =False, height = 120, width = 120, p=1),\n",
    "    RandomResizedCrop(always_apply = False, height = 120, width = 120, p=1),\n",
    "    ColorJitter(always_apply = False, brightness = 0.2, contrast = 0.2, saturation = 0.2, hue = 0.2, p=1),\n",
    "    Blur(always_apply = False, p=0.5),\n",
    "    Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225),always_apply = False, max_pixel_value = 255.0)],)\n",
    "\n",
    "# val_aug = Compose([\n",
    "#     SmallestMaxSize(always_apply = False, max_size = 256, p=1),\n",
    "#     CenterCrop(always_apply =False, height = 120, width = 120, p=1),\n",
    "#     Normalize(mean=(0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225) ,always_apply = False, max_pixel_value = 255., p =1)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "aad653bc-5f85-4cb3-8be0-f002f8d8c6dd",
    "outputId": "deeecff7-f61a-47c3-c042-88f961a976d9"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataAugmentor(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization = True,\n",
    "    augment=train_aug,\n",
    "    validation_split= 0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "927ee231-55a4-4d2a-bd97-f19348edf533"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1235545)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(brightness_range=(0.8,1.2),rotation_range=30,width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,fill_mode='nearest',shear_range=0.2,zoom_range=0.3,\n",
    "                                   validation_split=0.15)\n",
    "valid_datagen = ImageDataGenerator(validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32,shuffle=True,  subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = valid_datagen.flow(x_train, y_train,batch_size=25,shuffle=True,  subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "b095b127-c1ca-4bd2-80e2-1ab3676aa12c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/149229738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute quantities required for featurewise normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "# compute quantities required for featurewise normalization\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size=32, subset='training')\n",
    "validation_generator = datagen.flow(x_train, y_train, batch_size=32, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "28be0b8b-5b68-48a9-a5ec-35c30e1b6e80"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Input,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2d1e9136-adb0-4e80-8be4-ecdd1a448636",
    "outputId": "8d1cfa35-5317-422b-eaba-b74c092f5975"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 14:09:18.377704: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 14:09:19.857657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22307 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2021-11-23 14:09:19.860923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22307 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "94781440/94765736 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "base = ResNet50(include_top = False, weights = 'imagenet', input_shape = (image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "764b53ef-d531-4d93-824b-42774ec283ae",
    "outputId": "14112475-9a3c-4a63-a15f-87be1d764ff4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualkeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1148/4000656980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayered_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualkeras'"
     ]
    }
   ],
   "source": [
    "import visualkeras \n",
    "visualkeras.layered_view(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7b13117d-895a-4f1f-abdc-eac5d8a242c2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dense(2048, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "model  = Model(inputs = base.input, outputs = output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('WeightsResNet50 IDRND.h5', monitor = 'val_loss', save_best_only = True, mode = 'auto', verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67/1069951509.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 14:11:41.886179: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1226 [..............................] - ETA: 2:35:34 - loss: 2.5079 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 14:11:45.397951: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226/1226 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.8124\n",
      "Epoch 00001: val_loss improved from inf to 0.29316, saving model to WeightsResNet50 IDRND.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226/1226 [==============================] - 253s 200ms/step - loss: 0.5270 - accuracy: 0.8124 - val_loss: 0.2932 - val_accuracy: 0.8818\n",
      "Epoch 2/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8528\n",
      "Epoch 00002: val_loss improved from 0.29316 to 0.27541, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.3746 - accuracy: 0.8528 - val_loss: 0.2754 - val_accuracy: 0.8884\n",
      "Epoch 3/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8641\n",
      "Epoch 00003: val_loss improved from 0.27541 to 0.23019, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.3483 - accuracy: 0.8641 - val_loss: 0.2302 - val_accuracy: 0.9107\n",
      "Epoch 4/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8719\n",
      "Epoch 00004: val_loss improved from 0.23019 to 0.19103, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 241s 196ms/step - loss: 0.3302 - accuracy: 0.8719 - val_loss: 0.1910 - val_accuracy: 0.9241\n",
      "Epoch 5/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.3103 - accuracy: 0.8804\n",
      "Epoch 00005: val_loss improved from 0.19103 to 0.18168, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 241s 197ms/step - loss: 0.3103 - accuracy: 0.8804 - val_loss: 0.1817 - val_accuracy: 0.9296\n",
      "Epoch 6/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8830\n",
      "Epoch 00006: val_loss improved from 0.18168 to 0.18124, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 241s 196ms/step - loss: 0.3038 - accuracy: 0.8830 - val_loss: 0.1812 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.8895\n",
      "Epoch 00007: val_loss did not improve from 0.18124\n",
      "1226/1226 [==============================] - 241s 197ms/step - loss: 0.2918 - accuracy: 0.8895 - val_loss: 0.1915 - val_accuracy: 0.9274\n",
      "Epoch 8/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.8904 - ETA\n",
      "Epoch 00008: val_loss improved from 0.18124 to 0.16588, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2857 - accuracy: 0.8904 - val_loss: 0.1659 - val_accuracy: 0.9373\n",
      "Epoch 9/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.8927\n",
      "Epoch 00009: val_loss did not improve from 0.16588\n",
      "1226/1226 [==============================] - 241s 197ms/step - loss: 0.2781 - accuracy: 0.8927 - val_loss: 0.1904 - val_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.8962\n",
      "Epoch 00010: val_loss did not improve from 0.16588\n",
      "1226/1226 [==============================] - 241s 197ms/step - loss: 0.2715 - accuracy: 0.8962 - val_loss: 0.1820 - val_accuracy: 0.9277\n",
      "Epoch 11/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.8976\n",
      "Epoch 00011: val_loss improved from 0.16588 to 0.14548, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.2646 - accuracy: 0.8976 - val_loss: 0.1455 - val_accuracy: 0.9454\n",
      "Epoch 12/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9012\n",
      "Epoch 00012: val_loss did not improve from 0.14548\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2591 - accuracy: 0.9012 - val_loss: 0.1789 - val_accuracy: 0.9319\n",
      "Epoch 13/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9052\n",
      "Epoch 00013: val_loss did not improve from 0.14548\n",
      "1226/1226 [==============================] - 241s 197ms/step - loss: 0.2495 - accuracy: 0.9052 - val_loss: 0.1615 - val_accuracy: 0.9387\n",
      "Epoch 14/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9076\n",
      "Epoch 00014: val_loss improved from 0.14548 to 0.14257, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 247s 201ms/step - loss: 0.2461 - accuracy: 0.9076 - val_loss: 0.1426 - val_accuracy: 0.9454\n",
      "Epoch 15/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9062\n",
      "Epoch 00015: val_loss did not improve from 0.14257\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2527 - accuracy: 0.9062 - val_loss: 0.1528 - val_accuracy: 0.9432\n",
      "Epoch 16/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.9088\n",
      "Epoch 00016: val_loss improved from 0.14257 to 0.12551, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 240s 196ms/step - loss: 0.2436 - accuracy: 0.9088 - val_loss: 0.1255 - val_accuracy: 0.9513\n",
      "Epoch 17/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9109\n",
      "Epoch 00017: val_loss did not improve from 0.12551\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2419 - accuracy: 0.9109 - val_loss: 0.1343 - val_accuracy: 0.9523\n",
      "Epoch 18/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9116\n",
      "Epoch 00018: val_loss did not improve from 0.12551\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2361 - accuracy: 0.9116 - val_loss: 0.1283 - val_accuracy: 0.9529\n",
      "Epoch 19/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9119\n",
      "Epoch 00019: val_loss did not improve from 0.12551\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2355 - accuracy: 0.9119 - val_loss: 0.1289 - val_accuracy: 0.9548\n",
      "Epoch 20/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9125\n",
      "Epoch 00020: val_loss did not improve from 0.12551\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.2327 - accuracy: 0.9125 - val_loss: 0.1483 - val_accuracy: 0.9425\n",
      "Epoch 21/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9135\n",
      "Epoch 00021: val_loss improved from 0.12551 to 0.11770, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 247s 201ms/step - loss: 0.2346 - accuracy: 0.9135 - val_loss: 0.1177 - val_accuracy: 0.9561\n",
      "Epoch 22/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9144\n",
      "Epoch 00022: val_loss did not improve from 0.11770\n",
      "1226/1226 [==============================] - 248s 202ms/step - loss: 0.2269 - accuracy: 0.9144 - val_loss: 0.1221 - val_accuracy: 0.9552\n",
      "Epoch 23/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.9154\n",
      "Epoch 00023: val_loss did not improve from 0.11770\n",
      "1226/1226 [==============================] - 245s 199ms/step - loss: 0.2255 - accuracy: 0.9154 - val_loss: 0.1457 - val_accuracy: 0.9481\n",
      "Epoch 24/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9180\n",
      "Epoch 00024: val_loss improved from 0.11770 to 0.11723, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.2178 - accuracy: 0.9180 - val_loss: 0.1172 - val_accuracy: 0.9569\n",
      "Epoch 25/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9183\n",
      "Epoch 00025: val_loss did not improve from 0.11723\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.2161 - accuracy: 0.9183 - val_loss: 0.1256 - val_accuracy: 0.9548\n",
      "Epoch 26/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9175\n",
      "Epoch 00026: val_loss improved from 0.11723 to 0.11588, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.2211 - accuracy: 0.9175 - val_loss: 0.1159 - val_accuracy: 0.9582\n",
      "Epoch 27/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9205\n",
      "Epoch 00027: val_loss did not improve from 0.11588\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.2139 - accuracy: 0.9205 - val_loss: 0.1496 - val_accuracy: 0.9461\n",
      "Epoch 28/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9212\n",
      "Epoch 00028: val_loss improved from 0.11588 to 0.10714, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.2135 - accuracy: 0.9212 - val_loss: 0.1071 - val_accuracy: 0.9617\n",
      "Epoch 29/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9215\n",
      "Epoch 00029: val_loss did not improve from 0.10714\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.2089 - accuracy: 0.9215 - val_loss: 0.1076 - val_accuracy: 0.9607\n",
      "Epoch 30/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9220\n",
      "Epoch 00030: val_loss did not improve from 0.10714\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.2096 - accuracy: 0.9220 - val_loss: 0.1147 - val_accuracy: 0.9585\n",
      "Epoch 31/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9234\n",
      "Epoch 00031: val_loss did not improve from 0.10714\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.2077 - accuracy: 0.9234 - val_loss: 0.1073 - val_accuracy: 0.9611\n",
      "Epoch 32/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9227\n",
      "Epoch 00032: val_loss did not improve from 0.10714\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.2087 - accuracy: 0.9227 - val_loss: 0.1074 - val_accuracy: 0.9624\n",
      "Epoch 33/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9220\n",
      "Epoch 00033: val_loss improved from 0.10714 to 0.10367, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 249s 203ms/step - loss: 0.2098 - accuracy: 0.9220 - val_loss: 0.1037 - val_accuracy: 0.9620\n",
      "Epoch 34/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9263\n",
      "Epoch 00034: val_loss did not improve from 0.10367\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.2011 - accuracy: 0.9263 - val_loss: 0.1308 - val_accuracy: 0.9537\n",
      "Epoch 35/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9280\n",
      "Epoch 00035: val_loss did not improve from 0.10367\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1956 - accuracy: 0.9280 - val_loss: 0.1063 - val_accuracy: 0.9592\n",
      "Epoch 36/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9265\n",
      "Epoch 00036: val_loss did not improve from 0.10367\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1999 - accuracy: 0.9265 - val_loss: 0.1254 - val_accuracy: 0.9496\n",
      "Epoch 37/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9283\n",
      "Epoch 00037: val_loss improved from 0.10367 to 0.10223, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1974 - accuracy: 0.9283 - val_loss: 0.1022 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.9258\n",
      "Epoch 00038: val_loss improved from 0.10223 to 0.09819, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1987 - accuracy: 0.9258 - val_loss: 0.0982 - val_accuracy: 0.9646\n",
      "Epoch 39/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.9283\n",
      "Epoch 00039: val_loss did not improve from 0.09819\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1938 - accuracy: 0.9283 - val_loss: 0.1085 - val_accuracy: 0.9618\n",
      "Epoch 40/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9300\n",
      "Epoch 00040: val_loss did not improve from 0.09819\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1956 - accuracy: 0.9300 - val_loss: 0.1224 - val_accuracy: 0.9543\n",
      "Epoch 41/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9280\n",
      "Epoch 00041: val_loss did not improve from 0.09819\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1960 - accuracy: 0.9280 - val_loss: 0.1050 - val_accuracy: 0.9624\n",
      "Epoch 42/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9308\n",
      "Epoch 00042: val_loss improved from 0.09819 to 0.09080, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1900 - accuracy: 0.9308 - val_loss: 0.0908 - val_accuracy: 0.9663\n",
      "Epoch 43/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9308\n",
      "Epoch 00043: val_loss did not improve from 0.09080\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1885 - accuracy: 0.9308 - val_loss: 0.1145 - val_accuracy: 0.9582\n",
      "Epoch 44/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9316\n",
      "Epoch 00044: val_loss did not improve from 0.09080\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1842 - accuracy: 0.9316 - val_loss: 0.1256 - val_accuracy: 0.9553\n",
      "Epoch 45/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9323\n",
      "Epoch 00045: val_loss did not improve from 0.09080\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1884 - accuracy: 0.9323 - val_loss: 0.0994 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9296\n",
      "Epoch 00046: val_loss did not improve from 0.09080\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1931 - accuracy: 0.9296 - val_loss: 0.1045 - val_accuracy: 0.9617\n",
      "Epoch 47/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.9309\n",
      "Epoch 00047: val_loss improved from 0.09080 to 0.08952, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1895 - accuracy: 0.9309 - val_loss: 0.0895 - val_accuracy: 0.9663\n",
      "Epoch 48/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9337\n",
      "Epoch 00048: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1813 - accuracy: 0.9337 - val_loss: 0.0948 - val_accuracy: 0.9644\n",
      "Epoch 49/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9304\n",
      "Epoch 00049: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1902 - accuracy: 0.9304 - val_loss: 0.0946 - val_accuracy: 0.9656\n",
      "Epoch 50/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9323\n",
      "Epoch 00050: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1837 - accuracy: 0.9323 - val_loss: 0.0963 - val_accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9334\n",
      "Epoch 00051: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 242s 198ms/step - loss: 0.1833 - accuracy: 0.9334 - val_loss: 0.1324 - val_accuracy: 0.9537\n",
      "Epoch 52/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9328\n",
      "Epoch 00052: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 242s 197ms/step - loss: 0.1828 - accuracy: 0.9328 - val_loss: 0.0948 - val_accuracy: 0.9659\n",
      "Epoch 53/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9326\n",
      "Epoch 00053: val_loss did not improve from 0.08952\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1875 - accuracy: 0.9326 - val_loss: 0.1014 - val_accuracy: 0.9657\n",
      "Epoch 54/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9361\n",
      "Epoch 00054: val_loss improved from 0.08952 to 0.08952, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1783 - accuracy: 0.9361 - val_loss: 0.0895 - val_accuracy: 0.9662\n",
      "Epoch 55/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9347\n",
      "Epoch 00055: val_loss improved from 0.08952 to 0.08485, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1783 - accuracy: 0.9347 - val_loss: 0.0849 - val_accuracy: 0.9669\n",
      "Epoch 56/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9350\n",
      "Epoch 00056: val_loss did not improve from 0.08485\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1792 - accuracy: 0.9350 - val_loss: 0.0851 - val_accuracy: 0.9698\n",
      "Epoch 57/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9333\n",
      "Epoch 00057: val_loss improved from 0.08485 to 0.08235, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1808 - accuracy: 0.9333 - val_loss: 0.0823 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9357\n",
      "Epoch 00058: val_loss improved from 0.08235 to 0.08227, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1734 - accuracy: 0.9357 - val_loss: 0.0823 - val_accuracy: 0.9692\n",
      "Epoch 59/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9353\n",
      "Epoch 00059: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 246s 201ms/step - loss: 0.1790 - accuracy: 0.9353 - val_loss: 0.0880 - val_accuracy: 0.9696\n",
      "Epoch 60/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9365\n",
      "Epoch 00060: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1748 - accuracy: 0.9365 - val_loss: 0.0997 - val_accuracy: 0.9683\n",
      "Epoch 61/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9349\n",
      "Epoch 00061: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1819 - accuracy: 0.9349 - val_loss: 0.0862 - val_accuracy: 0.9709\n",
      "Epoch 62/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9372\n",
      "Epoch 00062: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1695 - accuracy: 0.9372 - val_loss: 0.0869 - val_accuracy: 0.9694\n",
      "Epoch 63/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9370\n",
      "Epoch 00063: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1754 - accuracy: 0.9370 - val_loss: 0.0977 - val_accuracy: 0.9662\n",
      "Epoch 64/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9367\n",
      "Epoch 00064: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1739 - accuracy: 0.9367 - val_loss: 0.0864 - val_accuracy: 0.9698\n",
      "Epoch 65/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9373\n",
      "Epoch 00065: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 245s 199ms/step - loss: 0.1747 - accuracy: 0.9373 - val_loss: 0.0838 - val_accuracy: 0.9695\n",
      "Epoch 66/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9386\n",
      "Epoch 00066: val_loss did not improve from 0.08227\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1697 - accuracy: 0.9386 - val_loss: 0.0970 - val_accuracy: 0.9650\n",
      "Epoch 67/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9356\n",
      "Epoch 00067: val_loss improved from 0.08227 to 0.07523, saving model to WeightsResNet50 IDRND.h5\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1767 - accuracy: 0.9356 - val_loss: 0.0752 - val_accuracy: 0.9748\n",
      "Epoch 68/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9391\n",
      "Epoch 00068: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 245s 200ms/step - loss: 0.1698 - accuracy: 0.9391 - val_loss: 0.0810 - val_accuracy: 0.9705\n",
      "Epoch 69/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9389\n",
      "Epoch 00069: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1690 - accuracy: 0.9389 - val_loss: 0.0808 - val_accuracy: 0.9707\n",
      "Epoch 70/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9399\n",
      "Epoch 00070: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1681 - accuracy: 0.9399 - val_loss: 0.0996 - val_accuracy: 0.9634\n",
      "Epoch 71/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9359\n",
      "Epoch 00071: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1752 - accuracy: 0.9359 - val_loss: 0.0858 - val_accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9403\n",
      "Epoch 00072: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1662 - accuracy: 0.9403 - val_loss: 0.0960 - val_accuracy: 0.9670\n",
      "Epoch 73/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9393\n",
      "Epoch 00073: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1668 - accuracy: 0.9393 - val_loss: 0.0939 - val_accuracy: 0.9659\n",
      "Epoch 74/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9394\n",
      "Epoch 00074: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 242s 198ms/step - loss: 0.1698 - accuracy: 0.9394 - val_loss: 0.0880 - val_accuracy: 0.9691\n",
      "Epoch 75/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9410\n",
      "Epoch 00075: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 244s 199ms/step - loss: 0.1642 - accuracy: 0.9410 - val_loss: 0.0921 - val_accuracy: 0.9660\n",
      "Epoch 76/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9388\n",
      "Epoch 00076: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1690 - accuracy: 0.9388 - val_loss: 0.0938 - val_accuracy: 0.9665\n",
      "Epoch 77/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9404\n",
      "Epoch 00077: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1658 - accuracy: 0.9404 - val_loss: 0.1014 - val_accuracy: 0.9643\n",
      "Epoch 78/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9395\n",
      "Epoch 00078: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1668 - accuracy: 0.9395 - val_loss: 0.0948 - val_accuracy: 0.9640\n",
      "Epoch 79/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9386\n",
      "Epoch 00079: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1695 - accuracy: 0.9386 - val_loss: 0.0848 - val_accuracy: 0.9691\n",
      "Epoch 80/100\n",
      "1226/1226 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9405\n",
      "Epoch 00080: val_loss did not improve from 0.07523\n",
      "1226/1226 [==============================] - 243s 198ms/step - loss: 0.1607 - accuracy: 0.9405 - val_loss: 0.0926 - val_accuracy: 0.9665\n",
      "Epoch 81/100\n",
      "  82/1226 [=>............................] - ETA: 3:40 - loss: 0.1812 - accuracy: 0.9352"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator, \n",
    "    epochs = 100,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"ModelResNet50_IDRND.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs,train_accuracy,'g',label='Training Accuracy')\n",
    "plt.plot(epochs,validation_accuracy,'b',label='Validation Accuracy')\n",
    "plt.title('Training Vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs,train_loss,'g', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('WeightsResNet50 IDRND(2).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "resnet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "biometric",
   "language": "python",
   "name": "biometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
